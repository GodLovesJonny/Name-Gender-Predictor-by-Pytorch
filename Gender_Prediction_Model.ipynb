{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "from torchvision import models\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "def save_net(fname, net):\n",
    "    with h5py.File(fname, 'w') as h5f:\n",
    "        for k, v in net.state_dict().items():\n",
    "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
    "def load_net(fname, net):\n",
    "    with h5py.File(fname, 'r') as h5f:\n",
    "        for k, v in net.state_dict().items():        \n",
    "            param = torch.from_numpy(np.asarray(h5f[k]))         \n",
    "            v.copy_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n",
    "    if is_best:\n",
    "        torch.save(state, './best_model/'+task_id+'model_best.pth.tar')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'gpu': '0',\n",
    "    'task':'./best_model/',\n",
    "    'original_lr':0.0004,\n",
    "    'lr':0.0004,\n",
    "    'batch_size':4,\n",
    "    'momentum':0.95,\n",
    "    'decay':5*1e-4,\n",
    "    'start_epoch':0,\n",
    "    'epochs':600,\n",
    "    'steps':[-1,1,100,150],\n",
    "    'scales':[1,1,1,1],\n",
    "    'workers':4,\n",
    "    'seed':time.time(),\n",
    "    'print_freq':50,\n",
    "    'pre':'./best_model/0.6699000587889476model_best.pth.tar',\n",
    "    'test_freq':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/male.txt') as f:\n",
    "    male_names = f.readlines()\n",
    "\n",
    "with open('./Data/female.txt') as f:\n",
    "    female_names = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(male_names)):\n",
    "    name = male_names[i][:-1]\n",
    "    male_names[i] = name\n",
    "    \n",
    "for i in range(len(female_names)):\n",
    "    name = female_names[i][:-1]\n",
    "    female_names[i] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "mf_names = []\n",
    "\n",
    "for f_name in female_names:\n",
    "    if f_name in male_names:\n",
    "        mf_names.append(f_name)\n",
    "\n",
    "print(len(mf_names))\n",
    "# print(mf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_entries = 7214\n",
      "Max_len = 30\n"
     ]
    }
   ],
   "source": [
    "female_names = [f_name.lower() for f_name in female_names if not f_name in mf_names]\n",
    "male_names = [m_name.lower() for m_name in male_names if not m_name in mf_names]\n",
    "\n",
    "total_entries = len(female_names) + len(male_names)\n",
    "max_len = len(max(male_names, key=len)) + len(max(female_names, key=len))\n",
    "print(\"Total_entries = %d\" % total_entries)\n",
    "print(\"Max_len = %d\" % max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_char = 29\n"
     ]
    }
   ],
   "source": [
    "chars = set(\"\".join(male_names) + \"\".join(female_names))\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))\n",
    "print('Total_char = %d' % len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((total_entries, max_len, len(chars)))\n",
    "y = np.zeros((total_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 30, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(male_names):\n",
    "    for t, char in enumerate(name):\n",
    "        X[i, t, char2index[char]] = 1\n",
    "#     y[i, 0]  = 1\n",
    "    \n",
    "for i, name in enumerate(female_names):\n",
    "    for t, char in enumerate(name):\n",
    "        X[i + len(male_names), t, char2index[char]] = 1\n",
    "    y[i + len(male_names)]  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset():\n",
    "    \n",
    "    def __init__(self, root, shuffle=True,  train=False, batch_size=1, num_workers=4):\n",
    "            random.shuffle(root)\n",
    "            self.nSamples = len(root)\n",
    "            self.line = root\n",
    "            self.train = train\n",
    "            self.batch_size = batch_size\n",
    "            self.num_workers = num_workers\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error'\n",
    "        return X[self.line[index]], y[self.line[index]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=29, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=512, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(max_len, 2)\n",
    "    \n",
    "    def forward(self, names_in):\n",
    "        out,_ = self.lstm1(names_in)\n",
    "        out = F.dropout(out, p=0.2)\n",
    "        out,_ = self.lstm2(out)\n",
    "        out = out[:, :, -1]\n",
    "        out = F.dropout(out, p=0.2)\n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm1): LSTM(29, 512, batch_first=True)\n",
      "  (lstm2): LSTM(512, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "# print(optimizer)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epoch, train_list):\n",
    "    losses = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ListDataset(train_list,\n",
    "                       shuffle=True, \n",
    "                       train=True, \n",
    "                       batch_size=1,\n",
    "                       num_workers=args['workers']),\n",
    "        batch_size=args['batch_size'],\n",
    "        drop_last=True)\n",
    "    \n",
    "#     print(train_loader)\n",
    "    \n",
    "    for i, (names, genders) in enumerate(train_loader):\n",
    "        names_in = torch.from_numpy(np.asarray(names)).type(torch.FloatTensor)\n",
    "        names_in = Variable(names_in)\n",
    "        genders_in = torch.from_numpy(np.asarray(genders)).type(torch.LongTensor)\n",
    "        genders_in = Variable(genders_in)\n",
    "        \n",
    "        model.train()\n",
    "        end = time.time()\n",
    "\n",
    "        out = net(names_in)\n",
    "#         print(out)\n",
    "#         print(out.shape)\n",
    "#         print(genders_in.shape)\n",
    "#         print(genders_in)\n",
    "        loss = loss_func(out, genders_in)\n",
    "        losses.update(loss, names_in.size(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args['print_freq'] == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      .format(\n",
    "                       epoch, i, len(train_loader), batch_time=batch_time, loss=losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathanwang/.local/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1803]\tTime 0.457 (0.457)\tData 0.000 (0.000)\tLoss 0.7205 (0.7205)\t\n",
      "Epoch: [0][50/1803]\tTime 0.359 (0.428)\tData 0.000 (0.000)\tLoss 1.0444 (0.6441)\t\n",
      "Epoch: [0][100/1803]\tTime 0.501 (0.422)\tData 0.000 (0.000)\tLoss 0.7997 (0.6274)\t\n",
      "Epoch: [0][150/1803]\tTime 0.587 (0.423)\tData 0.000 (0.000)\tLoss 0.3558 (0.6295)\t\n",
      "Epoch: [0][200/1803]\tTime 0.357 (0.427)\tData 0.000 (0.000)\tLoss 0.7616 (0.6316)\t\n",
      "Epoch: [0][250/1803]\tTime 0.342 (0.427)\tData 0.000 (0.000)\tLoss 0.3362 (0.6281)\t\n",
      "Epoch: [0][300/1803]\tTime 0.342 (0.415)\tData 0.000 (0.000)\tLoss 0.7621 (0.6277)\t\n",
      "Epoch: [0][350/1803]\tTime 0.356 (0.406)\tData 0.000 (0.000)\tLoss 0.5779 (0.6325)\t\n",
      "Epoch: [0][400/1803]\tTime 0.456 (0.400)\tData 0.000 (0.000)\tLoss 0.5816 (0.6365)\t\n",
      "Epoch: [0][450/1803]\tTime 0.347 (0.403)\tData 0.000 (0.000)\tLoss 0.5693 (0.6416)\t\n",
      "Epoch: [0][500/1803]\tTime 0.373 (0.404)\tData 0.000 (0.000)\tLoss 0.6073 (0.6472)\t\n",
      "Epoch: [0][550/1803]\tTime 0.346 (0.402)\tData 0.000 (0.000)\tLoss 0.4287 (0.6490)\t\n",
      "Epoch: [0][600/1803]\tTime 0.377 (0.405)\tData 0.000 (0.000)\tLoss 0.5373 (0.6474)\t\n",
      "Epoch: [0][650/1803]\tTime 0.380 (0.410)\tData 0.000 (0.000)\tLoss 0.8203 (0.6522)\t\n",
      "Epoch: [0][700/1803]\tTime 0.401 (0.416)\tData 0.000 (0.000)\tLoss 0.3208 (0.6528)\t\n",
      "Epoch: [0][750/1803]\tTime 0.769 (0.422)\tData 0.000 (0.000)\tLoss 0.6461 (0.6539)\t\n",
      "Epoch: [0][800/1803]\tTime 1.048 (0.426)\tData 0.000 (0.000)\tLoss 0.7183 (0.6511)\t\n",
      "Epoch: [0][850/1803]\tTime 0.379 (0.429)\tData 0.000 (0.000)\tLoss 0.5740 (0.6524)\t\n",
      "Epoch: [0][900/1803]\tTime 0.376 (0.430)\tData 0.000 (0.000)\tLoss 0.8063 (0.6537)\t\n",
      "Epoch: [0][950/1803]\tTime 0.392 (0.431)\tData 0.000 (0.000)\tLoss 0.3366 (0.6523)\t\n",
      "Epoch: [0][1000/1803]\tTime 0.382 (0.433)\tData 0.000 (0.000)\tLoss 0.5656 (0.6535)\t\n",
      "Epoch: [0][1050/1803]\tTime 0.726 (0.435)\tData 0.000 (0.000)\tLoss 0.6499 (0.6545)\t\n",
      "Epoch: [0][1100/1803]\tTime 0.349 (0.436)\tData 0.000 (0.000)\tLoss 0.5652 (0.6552)\t\n",
      "Epoch: [0][1150/1803]\tTime 0.386 (0.435)\tData 0.000 (0.000)\tLoss 0.5701 (0.6573)\t\n",
      "Epoch: [0][1200/1803]\tTime 0.564 (0.437)\tData 0.000 (0.000)\tLoss 0.3283 (0.6584)\t\n",
      "Epoch: [0][1250/1803]\tTime 0.838 (0.444)\tData 0.000 (0.000)\tLoss 0.3134 (0.6601)\t\n",
      "Epoch: [0][1300/1803]\tTime 0.665 (0.450)\tData 0.000 (0.000)\tLoss 0.6774 (0.6583)\t\n",
      "Epoch: [0][1350/1803]\tTime 0.533 (0.458)\tData 0.000 (0.000)\tLoss 0.8144 (0.6584)\t\n",
      "Epoch: [0][1400/1803]\tTime 0.829 (0.468)\tData 0.000 (0.000)\tLoss 0.5632 (0.6582)\t\n",
      "Epoch: [0][1450/1803]\tTime 0.876 (0.479)\tData 0.000 (0.000)\tLoss 0.5635 (0.6571)\t\n",
      "Epoch: [0][1500/1803]\tTime 1.094 (0.493)\tData 0.000 (0.000)\tLoss 0.6456 (0.6600)\t\n",
      "Epoch: [0][1550/1803]\tTime 0.634 (0.498)\tData 0.000 (0.000)\tLoss 0.8124 (0.6616)\t\n",
      "Epoch: [0][1600/1803]\tTime 0.588 (0.504)\tData 0.000 (0.000)\tLoss 0.5491 (0.6622)\t\n",
      "Epoch: [0][1650/1803]\tTime 0.598 (0.508)\tData 0.000 (0.000)\tLoss 0.4813 (0.6623)\t\n",
      "Epoch: [0][1700/1803]\tTime 0.569 (0.512)\tData 0.000 (0.000)\tLoss 0.5633 (0.6613)\t\n",
      "Epoch: [0][1750/1803]\tTime 0.745 (0.517)\tData 0.000 (0.000)\tLoss 0.5634 (0.6620)\t\n",
      "Epoch: [0][1800/1803]\tTime 0.604 (0.520)\tData 0.000 (0.000)\tLoss 0.5632 (0.6599)\t\n"
     ]
    }
   ],
   "source": [
    "train_list = [i for i in range(len(X))]\n",
    "for epoch in range(10):\n",
    "    train(net, optimizer, epoch, train_list)\n",
    "    torch.save(net.state_dict(), 'net_params.pkl')\n",
    "    print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a name: Jonathan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathanwang/.local/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Input a name: Lily\n",
      "Female\n",
      "Input a name: -1\n"
     ]
    }
   ],
   "source": [
    "# Apply.py\n",
    "def predict(model, name, max_len, chars, char2index):\n",
    "    name = name.lower()\n",
    "    q_name = torch.zeros((1, max_len, len(chars)))\n",
    "    for i, char in enumerate(name):\n",
    "        q_name[0, i, char2index[char]] = 1\n",
    "    prob = model(q_name)\n",
    "    return prob\n",
    "\n",
    "gender_predictor = Net()\n",
    "gender_predictor.load_state_dict(torch.load('net_params.pkl'))\n",
    "\n",
    "while True:\n",
    "    query_name = input('Input a name: ')\n",
    "    if query_name == '-1':\n",
    "        break\n",
    "    v = predict(gender_predictor, query_name, max_len, chars, char2index)[0]\n",
    "#     print(v)\n",
    "    if v[0] > v[1]:\n",
    "        print('Male')\n",
    "    else:\n",
    "        print('Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
